{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''语料'''\n",
    "corpus  = \"她的菜很好,她的菜很香,他的她很好,他的菜很香,他的她很好,很香的菜,很好的她,很菜的他,她的好,菜的香,他的菜,她很好,他很菜,菜很好\"\n",
    "corpus = corpus.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('的', 11), ('很', 11), ('菜', 9), ('她', 7), ('好', 7), ('他', 6), ('香', 4)]\n",
      "{'的': 0, '很': 1, '菜': 2, '她': 3, '好': 4, '他': 5, '香': 6}\n",
      "{0: '的', 1: '很', 2: '菜', 3: '她', 4: '好', 5: '他', 6: '香'}\n"
     ]
    }
   ],
   "source": [
    "'''语料预处理'''\n",
    "counter = Counter()\n",
    "for sentence in corpus:\n",
    "    for word in sentence:\n",
    "        counter[word] += 1\n",
    "counter = counter.most_common() #按照由大到小顺序返回前n个数据\n",
    "l = len(counter)\n",
    "word2id = {counter[i][0]:i for i in range(l)} #字典数据类型构建word2id\n",
    "id2word = {i :counter[i][0] for i in range(l)} #字典数据类型构建id2word\n",
    "print(counter)\n",
    "print(word2id)\n",
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2        0.2        0.16363636 0.12727273 0.12727273 0.10909091\n",
      " 0.07272727]\n",
      "[3 0 2 1 4]\n",
      "[3 0 2 1 6]\n",
      "[5 0 3 1 4]\n",
      "[5 0 2 1 6]\n",
      "[5 0 3 1 4]\n",
      "[1 6 0 2]\n",
      "[1 4 0 3]\n",
      "[1 2 0 5]\n",
      "[3 0 4]\n",
      "[2 0 6]\n",
      "[5 0 2]\n",
      "[3 1 4]\n",
      "[5 1 2]\n",
      "[2 1 4]\n",
      "[[0. 0. 5. 3. 1. 1. 1.]\n",
      " [0. 0. 2. 0. 6. 0. 3.]\n",
      " [2. 4. 0. 0. 0. 0. 0.]\n",
      " [3. 3. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [4. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "'''N-gram模型训练'''\n",
    "l = len(counter) #counter的长度，即词的个数\n",
    "S = sum(counter[i][1] for i in range(l))\n",
    "unigram = np.array([counter[i][1] for i in range(l)])/ S #1-gram\n",
    "print(unigram)\n",
    "\n",
    "for sentence in corpus:\n",
    "#     print (sentence)\n",
    "    print (np.array([word2id[word] for word in sentence]))#句子的id表示\n",
    "    \n",
    "bigram = np.zeros((l,l))\n",
    "for sentence in corpus:\n",
    "    for i in range(1,len(sentence)):\n",
    "        bigram[word2id[sentence[i-1]],word2id[sentence[i]]] += 1 #2-gram\n",
    "print(bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#对unigram解释"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[的         很            菜      她       好     他       香  ]\n",
    "[0.2        0.2        0.16363636 0.12727273 0.12727273 0.10909091 0.07272727] 每一个元素代表对应汉字出现频率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对bigram解释 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[[0. 0. 5. 3. 1. 1. 1.]    的 很 菜 她 好 他 香\n",
    " [0. 0. 2. 0. 6. 0. 3.]  的 0. 0. 5. 3. 1. 1. 1.   各元素表示的意思为：第m行字出线且该字下一个字为n列的字的次数。\n",
    " [2. 4. 0. 0. 0. 0. 0.]  很 0. 0. 2. 0. 6. 0. 3.   可以看出，每一行元素相加应该为1，所以进行归一化。\n",
    " [3. 3. 0. 0. 0. 0. 0.]  菜 2. 4. 0. 0. 0. 0. 0.\n",
    " [1. 0. 0. 0. 0. 0. 0.]  她 3. 3. 0. 0. 0. 0. 0.\n",
    " [4. 1. 0. 0. 0. 0. 0.]  好 1. 0. 0. 0. 0. 0. 0.\n",
    " [1. 0. 0. 0. 0. 0. 0.]] 他 4. 1. 0. 0. 0. 0. 0.\n",
    "                 香 1. 0. 0. 0. 0. 0. 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''句子概率'''\n",
    "def prob_1(sentence): #1-gram预测\n",
    "    sentence_list1 = [word2id[i] for i in sentence]\n",
    "    p = 0\n",
    "    for i in range(len(sentence_list1)):\n",
    "        p += unigram[sentence_list1[i]]\n",
    "    return p\n",
    "\n",
    "def prob_2(sentence):#2-gram预测\n",
    "    sentence_list2 = [word2id[i] for i in sentence]\n",
    "    p = 0\n",
    "    for i in range(1,len(sentence_list2)):\n",
    "        p += bigram[sentence_list2[i-1],sentence_list2[i]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07272727272727272 0.0\n"
     ]
    }
   ],
   "source": [
    "'''实际预测'''\n",
    "P1 = prob_1(\"香\")\n",
    "P2 = prob_2(\"的的\")\n",
    "print(P1,P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
